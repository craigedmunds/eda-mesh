version: '3'

vars:
  REGISTRY: '{{.REGISTRY | default "ghcr.io"}}'
  NAMESPACE: image-factory-kargo
  BUILDER_IMAGE: '{{.REGISTRY}}/craigedmunds/image-factory:{{.BUILDER_VERSION | default "latest"}}'

tasks:
  # ============================================================================
  # Primary Build Tasks (Convention: simple names for default actions)
  # ============================================================================

  build:
    desc: Build and push multi-arch image for any enrolled image (reads from images.yaml)
    summary: |
      Usage: task build IMAGE=backstage [TAG=v1.0.0]
      
      Full pipeline: clone ‚Üí build multi-arch ‚Üí push ‚Üí scan ‚Üí update state
    cmds:
      - task: _ensure-enrolled
        vars: {IMAGE: '{{.IMAGE}}'}
      - task: _build-multiarch
        vars: {IMAGE: '{{.IMAGE}}', TAG: '{{.TAG | default "latest"}}'}
      - task: _scan
        vars: {IMAGE: '{{.IMAGE}}', TAG: '{{.TAG | default "latest"}}'}
      - task: _update-state
        vars: {IMAGE: '{{.IMAGE}}', TAG: '{{.TAG | default "latest"}}'}
      - echo "‚úÖ Build complete - {{.REGISTRY}}/{{.IMAGE}}:{{.TAG | default "latest"}}"
    vars:
      IMAGE: '{{.IMAGE}}'
      TAG: '{{.TAG}}'
    requires:
      vars: [IMAGE]

  build:local:
    desc: Build locally for testing (single platform, no push)
    summary: |
      Usage: task build:local IMAGE=backstage
      
      Quick local build - current platform only, tags as :local
    cmds:
      - task: _ensure-enrolled
        vars: {IMAGE: '{{.IMAGE}}'}
      - |
        echo "üîß Local build for {{.IMAGE}}..."
        eval $(task _get-config -- {{.IMAGE}})
        
        docker build \
          --tag "$IMAGE_NAME:local" \
          --file "$DOCKERFILE" \
          "$CONTEXT" || \
        podman build \
          --tag "$IMAGE_NAME:local" \
          --file "$DOCKERFILE" \
          "$CONTEXT"
        
        echo "‚úÖ Local build complete: $IMAGE_NAME:local"
    vars:
      IMAGE: '{{.IMAGE}}'
    requires:
      vars: [IMAGE]

  build:scan-only:
    desc: Scan existing image without rebuilding
    cmds:
      - task: _scan
        vars: {IMAGE: '{{.IMAGE}}', TAG: '{{.TAG | default "latest"}}'}
    vars:
      IMAGE: '{{.IMAGE}}'
      TAG: '{{.TAG}}'
    requires:
      vars: [IMAGE]

  # ============================================================================
  # Builder Image Management
  # ============================================================================

  builder:
    desc: Build and push the Image Factory builder image itself
    cmds:
      - task: builder:build
      - task: builder:push

  builder:build:
    desc: Build the Image Factory builder image
    dir: builder
    cmds:
      - |
        echo "üèóÔ∏è  Building Image Factory builder image..."
        
        # Use docker or podman depending on what's available
        if command -v docker &> /dev/null; then
          docker build \
            --tag {{.BUILDER_IMAGE}} \
            --file Dockerfile \
            .
        elif command -v podman &> /dev/null; then
          podman build \
            --tag {{.BUILDER_IMAGE}} \
            --file Dockerfile \
            .
        else
          echo "‚ùå Neither docker nor podman found"
          exit 1
        fi

  builder:push:
    desc: Push the Image Factory builder image
    cmds:
      - |
        echo "üì§ Pushing Image Factory builder image..."
        
        if command -v docker &> /dev/null; then
          docker push {{.BUILDER_IMAGE}}
        elif command -v podman &> /dev/null; then
          podman push {{.BUILDER_IMAGE}}
        else
          echo "‚ùå Neither docker nor podman found"
          exit 1
        fi

  builder:test:
    desc: Test the builder image
    cmds:
      - |
        echo "üß™ Testing builder image..."
        
        if command -v docker &> /dev/null; then
          docker run --rm {{.BUILDER_IMAGE}} bash -c "
            echo '‚úì Task:' && task --version &&
            echo '‚úì Python:' && python3.11 --version &&
            echo '‚úì Podman:' && podman --version &&
            echo '‚úì Buildah:' && buildah --version &&
            echo '‚úì Trivy:' && trivy --version &&
            echo '‚úì kubectl:' && kubectl version --client
          "
        elif command -v podman &> /dev/null; then
          podman run --rm {{.BUILDER_IMAGE}} bash -c "
            echo '‚úì Task:' && task --version &&
            echo '‚úì Python:' && python3.11 --version &&
            echo '‚úì Podman:' && podman --version &&
            echo '‚úì Buildah:' && buildah --version &&
            echo '‚úì Trivy:' && trivy --version &&
            echo '‚úì kubectl:' && kubectl version --client
          "
        fi

  # ============================================================================
  # Primary Deploy Tasks
  # ============================================================================

  deploy:
    desc: Deploy Image Factory to K8s (primary deploy task)
    cmds:
      - task: cdk8s:synth
      - kubectl apply -f cdk8s/dist/image-factory.k8s.yaml
      - echo "‚úÖ Image Factory deployed to {{.NAMESPACE}}"

  # ============================================================================
  # Internal Build Pipeline Tasks (prefixed with _)
  # ============================================================================

  _ensure-enrolled:
    internal: true
    desc: Verify image is enrolled in images.yaml
    cmds:
      - |
        if ! grep -q "^- name: {{.IMAGE}}$" images.yaml; then
          echo "‚ùå Image '{{.IMAGE}}' not found in images.yaml"
          echo ""
          echo "Available images:"
          grep "^- name:" images.yaml | sed 's/- name: /  - /'
          exit 1
        fi
    vars:
      IMAGE: '{{.IMAGE}}'

  _get-config:
    internal: true
    desc: Extract configuration for an enrolled image from images.yaml
    cmds:
      - |
        python3 << 'EOF'
        import yaml
        import sys
        
        try:
            with open('images.yaml') as f:
                images = yaml.safe_load(f)
        except Exception as e:
            print(f"Error loading images.yaml: {e}", file=sys.stderr)
            sys.exit(1)
        
        image_name = '{{.IMAGE}}'
        img = next((i for i in images if i['name'] == image_name), None)
        
        if not img:
            print(f"Image '{image_name}' not found", file=sys.stderr)
            sys.exit(1)
        
        # Output as shell variables
        print(f"IMAGE_NAME={img['repository']}")
        print(f"DOCKERFILE={img['source']['dockerfile']}")
        print(f"CONTEXT={img['source'].get('context', '.')}")
        
        if 'repo' in img.get('source', {}):
            print(f"GIT_REPO=https://github.com/{img['source']['repo']}.git")
            print(f"GIT_BRANCH={img['source'].get('branch', 'main')}")
        EOF
    vars:
      IMAGE: '{{.IMAGE}}'

  _build-multiarch:
    internal: true
    desc: Build multi-arch image (amd64, arm64)
    cmds:
      - |
        echo "üèóÔ∏è  Building {{.IMAGE}} (multi-arch: amd64, arm64)..."
        
        # Get configuration from images.yaml
        eval $(task _get-config -- {{.IMAGE}})
        
        # Clone source if external repo
        BUILD_DIR="."
        if [ -n "$GIT_REPO" ]; then
          echo "üì• Cloning $GIT_REPO..."
          BUILD_DIR="/tmp/build-{{.IMAGE}}"
          rm -rf "$BUILD_DIR"
          git clone --depth 1 --branch "${GIT_BRANCH:-main}" "$GIT_REPO" "$BUILD_DIR"
          cd "$BUILD_DIR"
        fi
        
        # Ensure we have podman/buildah
        if ! command -v podman &> /dev/null || ! command -v buildah &> /dev/null; then
          echo "‚ùå Podman/Buildah not found. This task should run in the builder image."
          exit 1
        fi
        
        # Remove existing manifest if it exists
        podman manifest rm {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} 2>/dev/null || true
        
        # Create multi-arch manifest
        podman manifest create {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}}
        
        # Build for each architecture
        for ARCH in amd64 arm64; do
          echo "  üì¶ Building for $ARCH..."
          buildah bud \
            --format docker \
            --arch "$ARCH" \
            --manifest {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} \
            --layers \
            --file "$DOCKERFILE" \
            "$CONTEXT"
        done
        
        # Push manifest and all images
        echo "üì§ Pushing multi-arch manifest to {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}}..."
        podman manifest push \
          --all \
          {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} \
          docker://{{.REGISTRY}}/$IMAGE_NAME:{{.TAG}}
        
        # Get digest for state tracking
        DIGEST=$(podman manifest inspect {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} | jq -r '.digest')
        mkdir -p /tmp
        echo "DIGEST=$DIGEST" > /tmp/build-digest-{{.IMAGE}}.env
        echo "‚úÖ Build complete: {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} ($DIGEST)"
    vars:
      IMAGE: '{{.IMAGE}}'
      TAG: '{{.TAG}}'

  _scan:
    internal: true
    desc: Scan image with Trivy
    cmds:
      - |
        echo "üîç Scanning {{.IMAGE}}:{{.TAG}} for vulnerabilities..."
        mkdir -p .output
        
        eval $(task _get-config -- {{.IMAGE}})
        
        # Run Trivy scan
        trivy image \
          --severity HIGH,CRITICAL \
          --format sarif \
          --output .output/trivy-{{.IMAGE}}-{{.TAG}}.sarif \
          {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}} || true
        
        echo "üìä Vulnerability summary:"
        trivy image \
          --severity HIGH,CRITICAL \
          --format table \
          {{.REGISTRY}}/$IMAGE_NAME:{{.TAG}}
    vars:
      IMAGE: '{{.IMAGE}}'
      TAG: '{{.TAG}}'

  _update-state:
    internal: true
    desc: Update image factory state after build
    dir: app
    cmds:
      - |
        echo "üíæ Updating state for {{.IMAGE}}..."
        
        # Load digest from build
        if [ -f /tmp/build-digest-{{.IMAGE}}.env ]; then
          source /tmp/build-digest-{{.IMAGE}}.env
        else
          echo "‚ö†Ô∏è  No digest file found, skipping state update"
          exit 0
        fi
        
        # TODO: Implement state update in app.py
        # For now, just log the update
        echo "  Image: {{.IMAGE}}"
        echo "  Tag: {{.TAG}}"
        echo "  Digest: $DIGEST"
        echo "  (State update not yet implemented)"
    vars:
      IMAGE: '{{.IMAGE}}'
      TAG: '{{.TAG}}'

  # ============================================================================
  # Existing Tasks (Testing, Analysis, Status, etc.)
  # ============================================================================

  test:
    desc: Run all Image Factory tests
    cmds:
      - task: test:unit
      - task: test:integration
      - task: test:acceptance

  test:unit:setup:
    desc: "Set up Image Factory development environment"
    cmds:
      - task: app:setup
      - task: cdk8s:setup

  test:unit:
    desc: "Run unit tests for Image Factory"
    cmds:
      - task: app:test:unit
      - task: cdk8s:test:unit

  # Component-specific setup tasks
  test:integration:setup:
    desc: "Set up integration test"
    dir: tests/integration
    cmds:
      - cmd: echo "üîß Setting up integration test environment..."
        silent: true
      - cmd: |
          if [ -n "$CI" ]; then
            echo "CI environment detected, skipping virtual environment creation"
          else
            if [ ! -d ".venv" ]; then
              echo "Creating virtual environment..."
              python3 -m venv .venv
            fi
          fi
        silent: true
      - cmd: |
          echo "Installing dependencies..."
          if [ -n "$CI" ]; then
            pip install -e ".[dev]"
          else
            .venv/bin/pip install -e ".[dev]"
          fi
        silent: true

  test:integration:
    desc: "Run integration tests for Image Factory"
    dir: tests/integration
    cmds:
      - cmd: |
          if [ -n "$CI" ]; then
            python -m pytest test_integration.py -v
          else
            .venv/bin/python -m pytest test_integration.py -v
          fi
      
  test:acceptance:
    desc: "Run acceptance tests for Image Factory"
    dir: .
    cmds:
      - cmd: echo "üß™ Running Kargo acceptance tests..."
        silent: true
      - npm install
      - npm run test:kargo

  test:all:
    desc: "Run all tests for Image Factory"
    deps: [test:unit, test:integration, test:acceptance]

  # Component-specific setup tasks
  app:setup:
    desc: "Set up Image Factory app component"
    dir: app
    cmds:
      - cmd: echo "üîß Setting up Image Factory app environment..."
        silent: true
      - cmd: |
          if [ -n "$CI" ]; then
            echo "CI environment detected, skipping virtual environment creation"
          else
            if [ ! -d ".venv" ]; then
              echo "Creating virtual environment..."
              python3 -m venv .venv
            fi
          fi
        silent: true
      - cmd: |
          echo "Installing dependencies..."
          if [ -n "$CI" ]; then
            pip install -e ".[dev]"
          else
            .venv/bin/pip install -e ".[dev]"
          fi
        silent: true

  cdk8s:setup:
    desc: "Set up Image Factory CDK8s component"
    dir: cdk8s
    cmds:
      - cmd: echo "üîß Setting up Image Factory CDK8s environment..."
        silent: true
      - cmd: |
          if [ -n "$CI" ]; then
            echo "CI environment detected, skipping virtual environment creation"
          else
            if [ ! -d ".venv" ]; then
              echo "Creating virtual environment..."
              
              echo "Finding compatible Python version (>=3.10, <3.15)"
              python_cmd=""
              for py in python3.11 python3.12 python3.13 python3.10 python3; do
                if command -v "$py" >/dev/null 2>&1; then
                  if $py -c "import sys; exit(0 if (3, 10) <= sys.version_info[:2] < (3, 15) else 1)" 2>/dev/null; then
                    python_version=$($py -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
                    echo "Found compatible Python $python_version ($py)"
                    python_cmd="$py"
                    break
                  fi
                fi
              done
              
              if [ -z "$python_cmd" ]; then
                echo "Error: No compatible Python version found"
                echo "Required: Python >=3.10, <3.15 (GitHub Actions uses 3.11)"
                echo "Available Python versions:"
                for py in python3.11 python3.12 python3.13 python3.10 python3; do
                  if command -v "$py" >/dev/null 2>&1; then
                    version=$($py -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')" 2>/dev/null || echo "unknown")
                    echo "  $py: Python $version"
                  fi
                done
                exit 1
              fi
              
              $python_cmd -m venv .venv
            fi
          fi
        silent: true
      - cmd: |
          echo "Installing dependencies..."
          if [ -n "$CI" ]; then
            pip install -e ".[dev]"
          else
            .venv/bin/pip install -e ".[dev]"
          fi
        silent: true

  # Component-specific test tasks
  app:test:unit:
    desc: "Run unit tests for Image Factory app component"
    dir: app
    cmds:
      - cmd: echo "üß™ Running Image Factory app unit tests..."
        silent: true
      - cmd: |
          if [ -n "$CI" ]; then
            python -m pytest tests/test_app.py -v
          else
            .venv/bin/python -m pytest tests/test_app.py -v
          fi

  cdk8s:test:unit:
    desc: "Run unit tests for Image Factory CDK8s component"
    dir: cdk8s
    cmds:
      - cmd: echo "üß™ Running Image Factory CDK8s unit tests..."
        silent: true
      - cmd: |
          if [ -n "$CI" ]; then
            python -m pytest test_main.py -v
          else
            .venv/bin/python -m pytest test_main.py -v
          fi
      
  cdk8s:synth:
    desc: Synthesize CDK8s manifests
    dir: cdk8s
    cmds:
      - cmd: |
          if [ -n "$CI" ]; then
            python main.py
          else
            .venv/bin/python main.py
          fi
      
  cdk8s:deploy:
    desc: Deploy CDK8s manifests to cluster
    dir: cdk8s
    deps:
      - cdk8s:synth
    cmds:
      - kubectl apply -f dist/image-factory.k8s.yaml
      
  tool:run:
    desc: Run the image factory analysis tool
    dir: app
    cmds:
      - cmd: |
          if [ -n "$CI" ]; then
            python app.py --image-factory-dir ../
          else
            .venv/bin/python app.py --image-factory-dir ../
          fi

  tool:run:uv:
    desc: Run analysis tool for UV image (local testing)
    dir: app
    cmds:
      - cmd: |
          if [ -n "$CI" ]; then
            python app.py \
              --image uv \
              --tag "local-test" \
              --digest "sha256:local-test" \
              --dockerfile "apps/uv/Dockerfile" \
              --source-repo "craigedmunds/argocd-eda" \
              --source-provider "github" \
              --git-repo "https://github.com/craigedmunds/argocd-eda.git" \
              --git-branch "main" \
              --image-factory-dir ../
          else
            .venv/bin/python app.py \
              --image uv \
              --tag "local-test" \
              --digest "sha256:local-test" \
              --dockerfile "apps/uv/Dockerfile" \
              --source-repo "craigedmunds/argocd-eda" \
              --source-provider "github" \
              --git-repo "https://github.com/craigedmunds/argocd-eda.git" \
              --git-branch "main" \
              --image-factory-dir ../
          fi

  tool:run:backstage:
    desc: Run analysis tool for Backstage image (local testing)
    dir: app
    cmds:
      - cmd: |
          if [ -n "$CI" ]; then
            python app.py \
              --image backstage \
              --tag "local-test" \
              --digest "sha256:local-test" \
              --dockerfile "backstage/app/packages/backend/Dockerfile" \
              --source-repo "craigedmunds/argocd-eda" \
              --source-provider "github" \
              --git-repo "https://github.com/craigedmunds/argocd-eda.git" \
              --git-branch "main" \
              --image-factory-dir ../
          else
            .venv/bin/python app.py \
              --image backstage \
              --tag "local-test" \
              --digest "sha256:local-test" \
              --dockerfile "backstage/app/packages/backend/Dockerfile" \
              --source-repo "craigedmunds/argocd-eda" \
              --source-provider "github" \
              --git-repo "https://github.com/craigedmunds/argocd-eda.git" \
              --git-branch "main" \
              --image-factory-dir ../
          fi

  # Diagnostic and Status Tasks
  status:
    desc: Show comprehensive status of Image Factory components
    cmds:
      - echo "=== Image Factory Status Overview ==="
      - echo ""
      - echo "üìã Kargo Project Status:"
      - kubectl get project image-factory-kargo -n image-factory-kargo -o wide || echo "‚ùå Project not found"
      - echo ""
      - echo "üè≠ Warehouses Status:"
      - kubectl get warehouses -n image-factory-kargo -o wide || echo "‚ùå No warehouses found"
      - echo ""
      - echo "üé≠ Stages Status:"
      - kubectl get stages -n image-factory-kargo -o wide || echo "‚ùå No stages found"
      - echo ""
      - echo "üì¶ Freight Status:"
      - kubectl get freight -n image-factory-kargo -o wide || echo "‚ùå No freight found"
      - echo ""
      - echo "üöÄ Promotions Status (last 10):"
      - kubectl get promotions -n image-factory-kargo --sort-by=.metadata.creationTimestamp -o wide | tail -11 || echo "‚ùå No promotions found"
      - echo ""
      - echo "üî¨ AnalysisRuns Status:"
      - kubectl get analysisruns -n image-factory-kargo -o wide || echo "‚ùå No analysis runs found"
      - echo ""
      - echo "‚öôÔ∏è Jobs Status:"
      - kubectl get jobs -n image-factory-kargo -o wide || echo "‚ùå No jobs found"
      - echo ""
      - echo "üê≥ Pods Status:"
      - kubectl get pods -n image-factory-kargo -o wide || echo "‚ùå No pods found"

  logs:
    desc: Show logs from all running Image Factory components
    cmds:
      - echo "=== Image Factory Logs ==="
      - echo ""
      - echo "üìã Recent Events:"
      - kubectl get events -n image-factory-kargo --sort-by='.lastTimestamp' | tail -20 || echo "‚ùå No events found"
      - echo ""
      - echo "‚öôÔ∏è Job Logs (if any running):"
      - kubectl get jobs -n image-factory-kargo -o name | xargs -I {} kubectl logs -n image-factory-kargo {} --tail=50 || echo "‚ùå No jobs found"
      - echo ""
      - echo "üê≥ Pod Logs (if any running):"
      - kubectl get pods -n image-factory-kargo --field-selector=status.phase=Running -o name | xargs -I {} kubectl logs -n image-factory-kargo {} --tail=50 || echo "‚ùå No running pods found"

  logs:analysis:
    desc: Show logs from the most recent AnalysisRun
    cmds:
      - echo "=== Most Recent AnalysisRun Logs ==="
      - kubectl get analysisruns -n image-factory-kargo --sort-by=.metadata.creationTimestamp -o name | tail -1 | xargs -I {} kubectl describe -n image-factory-kargo {} || echo "‚ùå No AnalysisRuns found"

  logs:promotion:
    desc: Show logs from the most recent promotion
    cmds:
      - echo "=== Most Recent Promotion Logs ==="
      - kubectl get promotions -n image-factory-kargo --sort-by=.metadata.creationTimestamp -o name | tail -1 | xargs -I {} kubectl describe -n image-factory-kargo {} || echo "‚ùå No promotions found"

  debug:stage:
    desc: Debug a specific stage
    cmds:
      - echo "=== Stage Debug ==="
      - echo ""
      - echo "üìã Stage Configuration:"
      - kubectl get stage {{.STAGE | default "analyze-dockerfile-uv"}} -n image-factory-kargo -o yaml || echo "‚ùå Stage not found"
      - echo ""
      - echo "üöÄ Recent Promotions for this Stage:"
      - kubectl get promotions -n image-factory-kargo --sort-by=.metadata.creationTimestamp | grep {{.STAGE | default "analyze-dockerfile-uv"}} | tail -5 || echo "‚ùå No promotions found"
      - echo ""
      - echo "üî¨ Recent AnalysisRuns for this Stage:"
      - kubectl get analysisruns -n image-factory-kargo --sort-by=.metadata.creationTimestamp | grep {{.STAGE | default "analyze-dockerfile-uv"}} | tail -5 || echo "‚ùå No analysis runs found"

  debug:secrets:
    desc: Debug secret configuration and availability
    cmds:
      - echo "=== Secrets Debug ==="
      - echo ""
      - echo "üîê Available Secrets:"
      - kubectl get secrets -n image-factory-kargo || echo "‚ùå No secrets found"
      - echo ""
      - echo "üîç ServiceAccount Configuration:"
      - kubectl get serviceaccount image-factory -n image-factory-kargo -o yaml || echo "‚ùå ServiceAccount not found"

  clean:failed:
    desc: Clean up failed jobs and pods
    cmds:
      - echo "=== Cleaning Failed Resources ==="
      - echo ""
      - echo "üßπ Deleting failed jobs:"
      - kubectl delete jobs -n image-factory-kargo --field-selector status.successful=0 || echo "‚ùå No failed jobs to delete"
      - echo ""
      - echo "üßπ Deleting failed pods:"
      - kubectl delete pods -n image-factory-kargo --field-selector status.phase=Failed || echo "‚ùå No failed pods to delete"

  watch:
    desc: Watch Image Factory resources in real-time
    cmds:
      - echo "=== Watching Image Factory Resources ==="
      - echo "Press Ctrl+C to stop watching"
      - kubectl get promotions,analysisruns,jobs,pods -n image-factory-kargo -w